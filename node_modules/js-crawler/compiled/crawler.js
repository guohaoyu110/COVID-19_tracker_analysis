"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const executor_1 = require("./src/executor");
const request_1 = require("./src/request");
const response_1 = require("./src/response");
const configuration_1 = require("./src/configuration");
const state_1 = require("./src/state");
class Crawler {
    constructor() {
        this.state = new state_1.default({
            onCrawlingFinished: (urls) => {
                this.configuration.callbacks.finished(urls);
                this.workExecutor.stop();
            }
        });
        this.configuration = new configuration_1.default();
    }
    createExecutor() {
        return new executor_1.default({
            maxRatePerSecond: this.configuration.options.maxRequestsPerSecond,
            maxConcurrentTasks: this.configuration.options.maxConcurrentRequests
        });
    }
    createRequest(referer, url) {
        return new request_1.default({
            referer,
            url,
            userAgent: this.configuration.options.userAgent
        });
    }
    configure(options) {
        this.configuration.configure(options);
        return this;
    }
    crawl(urlOrOptions, onSuccess, onFailure, onAllFinished) {
        this.workExecutor = this.createExecutor();
        this.workExecutor.start();
        const url = this.configuration.updateAndReturnUrl(urlOrOptions, onSuccess, onFailure, onAllFinished);
        this.crawlUrl(url, null, this.configuration.options.depth);
        return this;
    }
    forgetCrawled() {
        this.state.clear();
    }
    crawlUrl(url, referer, depth) {
        //console.log('_crawlUrl: url = %s, depth = %s', url, depth);
        if ((depth === 0) || this.state.isVisitedUrl(url) || this.state.isBeingCrawled(url)) {
            return;
        }
        this.state.startedCrawling(url);
        this.workExecutor.submit(() => {
            if (this.state.isVisitedUrl(url) || !this.configuration.options.shouldCrawl(url)) {
                this.state.finishedCrawling(url);
                return Promise.resolve();
            }
            return this.createRequest(referer, url).submit()
                .then((success) => {
                if (this.state.isVisitedUrl(url)) {
                    //Was already crawled while the request has been processed, no need to call callbacks
                    return;
                }
                this.state.rememberVisitedUrls(success.visitedUrls);
                const resp = new response_1.default(success.response);
                const body = resp.getBody();
                if (this.configuration.options.shouldCrawl(success.lastVisitedUrl)) {
                    this.configuration.callbacks.success({
                        url: success.lastVisitedUrl,
                        status: success.response.statusCode,
                        content: body,
                        error: null,
                        response: success.response,
                        body: body,
                        referer: referer || ""
                    });
                    this.state.rememberCrawledUrl(success.lastVisitedUrl);
                    if (this.configuration.options.shouldCrawlLinksFrom(success.lastVisitedUrl) && depth > 1) {
                        const nextUrlsToCrawl = resp.getAllUrls(success.lastVisitedUrl, body, this.configuration.crawlingBehavior);
                        this.crawlUrls(nextUrlsToCrawl, success.lastVisitedUrl, depth - 1);
                    }
                }
            }).catch((failure) => {
                const resp = new response_1.default(failure.response);
                const body = resp.getBody();
                this.configuration.callbacks.failure({
                    url: url,
                    status: failure.response ? failure.response.statusCode : undefined,
                    content: body,
                    error: failure.error,
                    response: failure.response,
                    body: body,
                    referer: referer || ""
                });
                this.state.rememberCrawledUrl(url);
            }).then(() => {
                this.state.finishedCrawling(url);
            });
        });
    }
    crawlUrls(urls, referer, depth) {
        urls.forEach(url => this.crawlUrl(url, referer, depth));
    }
}
exports.default = Crawler;
//# sourceMappingURL=crawler.js.map